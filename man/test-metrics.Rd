% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/summarize.R
\name{test-metrics}
\alias{test-metrics}
\alias{ct_pos}
\alias{ct_neg}
\alias{ct_true_pos}
\alias{ct_false_pos}
\alias{ct_true_neg}
\alias{ct_false_neg}
\alias{ct_ppv}
\alias{ct_npv}
\alias{ct_fdr}
\alias{ct_for}
\alias{ct_sens}
\alias{ct_spec}
\alias{ct_fnr}
\alias{ct_fpr}
\title{Testing Metrics}
\usage{
ct_pos(dt)

ct_neg(dt)

ct_true_pos(dt)

ct_false_pos(dt)

ct_true_neg(dt)

ct_false_neg(dt)

ct_ppv(dt)

ct_npv(dt)

ct_fdr(dt)

ct_for(dt)

ct_sens(dt)

ct_spec(dt)

ct_fnr(dt)

ct_fpr(dt)
}
\arguments{
\item{dt}{`[data.table]` A distribution from `ct_dist()`}
}
\value{
`[numeric]` The specified metric
}
\description{
There are a number of metrics available to evaluate test performance.
These are the basics, from which one can calculate other metrics. See the
Wikipedia page on the
\href{https://en.wikipedia.org/wiki/Confusion_matrix#Table_of_confusion}{confusion matrix}
for more information on each metric.

`ct_pos()` is the proportion of positive tests (out of the organization)
`ct_neg()` is the proportion of negative tests (out of the organization)
`ct_true_pos()` is the proportion of true positive tests (out of org)
`ct_true_neg()` is the proportion of true negative tests (out of org)
`ct_false_pos()` is the proportion of false positive tests (out of org)
`ct_false_neg()` is the proportion of false negative tests (out of org)
`ct_ppv()` is the positive predictive value of a test
`ct_npv()` is the negative predictive value of a test
`ct_fdr()` is the false discovery rate of a test
`ct_for()` is the false omission rate of a test
`ct_sens()` is the sensitivity (true positive rate) of a test
`ct_spec()` is the specificity (true negative rate) of a test
`ct_fpr()` is the false positive rate of a test
`ct_fnr()` is the false negative rate of a test
}
