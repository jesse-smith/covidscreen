% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/summarize.R
\name{test-metrics}
\alias{test-metrics}
\alias{cs_pos}
\alias{cs_neg}
\alias{cs_true_pos}
\alias{cs_false_pos}
\alias{cs_true_neg}
\alias{cs_false_neg}
\alias{cs_ppv}
\alias{cs_npv}
\alias{cs_fdr}
\alias{cs_for}
\alias{cs_sens}
\alias{cs_spec}
\alias{cs_fnr}
\alias{cs_fpr}
\title{Testing Metrics}
\usage{
cs_pos(dt)

cs_neg(dt)

cs_true_pos(dt)

cs_false_pos(dt)

cs_true_neg(dt)

cs_false_neg(dt)

cs_ppv(dt)

cs_npv(dt)

cs_fdr(dt)

cs_for(dt)

cs_sens(dt)

cs_spec(dt)

cs_fnr(dt)

cs_fpr(dt)
}
\arguments{
\item{dt}{\code{[data.table]} A distribution from \code{cs_dist()}}
}
\value{
\code{[numeric]} The specified metric
}
\description{
There are a number of metrics available to evaluate test performance.
These are the basics, from which one can calculate other metrics. See the
Wikipedia page on the
\href{https://en.wikipedia.org/wiki/Confusion_matrix#Table_of_confusion}{confusion matrix}
for more information on each metric.

\code{cs_pos()} is the proportion of positive tests (out of the organization)
\code{cs_neg()} is the proportion of negative tests (out of the organization)
\code{cs_true_pos()} is the proportion of true positive tests (out of org)
\code{cs_true_neg()} is the proportion of true negative tests (out of org)
\code{cs_false_pos()} is the proportion of false positive tests (out of org)
\code{cs_false_neg()} is the proportion of false negative tests (out of org)
\code{cs_ppv()} is the positive predictive value of a test
\code{cs_npv()} is the negative predictive value of a test
\code{cs_fdr()} is the false discovery rate of a test
\code{cs_for()} is the false omission rate of a test
\code{cs_sens()} is the sensitivity (true positive rate) of a test
\code{cs_spec()} is the specificity (true negative rate) of a test
\code{cs_fpr()} is the false positive rate of a test
\code{cs_fnr()} is the false negative rate of a test
}
